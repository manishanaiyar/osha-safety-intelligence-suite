{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMs7lpPi2V0541nWhSyMKA4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manishanaiyar/osha-safety-intelligence-suite/blob/main/BERT_NLP_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**NLP-Based Narrative Classification (BERT)**\n",
        "\n",
        "**Objective:** Analyze raw incident narratives â€” actual text written by OSHA safety inspectors â€” and automatically classify them as High Risk (hospitalization) or Minor (outpatient/no treatment). Unlike structured models that read numbers and categories, BERT reads human language and understands context, making it uniquely suited for extracting risk signals from free-text incident descriptions.\n",
        "\n",
        "**Why BERT Over Traditional NLP?**\n",
        "Traditional NLP approaches (TF-IDF, bag-of-words) treat words as independent frequency counts. BERT is bidirectional â€” it reads every word in context of all surrounding words simultaneously:\n",
        "\n",
        "```\n",
        "Traditional: \"worker\" + \"finger\" + \"caught\" â†’ separate signals\n",
        "BERT:        \"worker's finger was caught in running machinery\"\n",
        "             â†’ understands the full contextual meaning as one unit\n",
        "\n",
        "This matters for OSHA narratives where the same words mean\n",
        "different things in different contexts:\n",
        "\"finger was amputated...treated and released\" â†’ Minor\n",
        "\"finger was amputated...hospitalized\"         â†’ High Risk\n",
        "```\n",
        "\n",
        "**Model Architecture:**\n",
        "```\n",
        "Input: Raw narrative text (up to 128 tokens)\n",
        "         â†“\n",
        "AutoTokenizer (bert-base-uncased)\n",
        "Converts words â†’ token IDs + attention mask\n",
        "MAX_LEN = 128 (captures ~95% of OSHA narratives fully)\n",
        "         â†“\n",
        "12 Transformer layers (110M parameters total)\n",
        "Each layer applies bidirectional self-attention\n",
        "         â†“\n",
        "[CLS] token â€” sentence-level representation\n",
        "         â†“\n",
        "Dropout layer (prevents overfitting)\n",
        "         â†“\n",
        "Linear classifier (768 â†’ 2)\n",
        "         â†“\n",
        "Logits [Minor_score, HighRisk_score]\n",
        "         â†“\n",
        "Softmax â†’ probability distribution\n",
        "```\n",
        "\n",
        "**Label Engineering:**\n",
        "```\n",
        "Hospitalized >= 1  â†’  Label 1 (High Risk)   17,280 cases (80.08%)\n",
        "Hospitalized  = 0  â†’  Label 0 (Minor)        4,298 cases (19.92%)\n",
        "\n",
        "IMPORTANT: Hospitalized measures administrative admission status,\n",
        "not injury severity. This distinction became critical during\n",
        "error analysis â€” see Key Finding below.\n",
        "```\n",
        "\n",
        "**Training Configuration:**\n",
        "```\n",
        "Base model:      bert-base-uncased (pre-trained on BookCorpus + Wikipedia)\n",
        "Fine-tuning:     5 epochs on 17,262 OSHA narratives\n",
        "Optimizer:       AdamW  lr=2e-5, eps=1e-8\n",
        "                 (recommended rate for BERT fine-tuning â€”\n",
        "                  large enough to learn, small enough not to\n",
        "                  destroy pre-trained knowledge)\n",
        "Loss function:   Weighted Cross Entropy\n",
        "                 Minor weight:     ~4.02Ã— (corrects 80/20 imbalance)\n",
        "                 High Risk weight: ~1.00Ã—\n",
        "Scheduler:       Linear warmup (10% of steps) â†’ linear decay\n",
        "                 Prevents large early updates corrupting\n",
        "                 pre-trained transformer weights\n",
        "Batch size:      16\n",
        "Hardware:        T4 GPU (CUDA)\n",
        "Train/Val split: 80/20 stratified (random_state=42)\n",
        "```\n",
        "\n",
        "**Training Results â€” 5 Epochs:**\n",
        "```\n",
        "Epoch    Train Loss    Val Loss    Val Accuracy\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  1         â€”            â€”            â€”\n",
        "  2         â€”            â€”            â€”\n",
        "  3         â€”            â€”            â€”\n",
        "  4         â€”            â€”            â€”\n",
        "  5         â€”            â€”            â€”\n",
        "(fill in from your training output)\n",
        "```\n",
        "\n",
        "**Validation Performance:**\n",
        "```\n",
        "=== Classification Report ===\n",
        "               Precision  Recall   F1     Support\n",
        "Minor (0)        0.75      0.85    0.80      860\n",
        "High Risk (1)    0.96      0.93    0.94     3456\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "Accuracy                           0.91     4316\n",
        "Macro avg        0.85      0.89    0.87     4316\n",
        "Weighted avg     0.92      0.91    0.92     4316\n",
        "\n",
        "=== Confusion Matrix ===\n",
        "True Negatives  (correctly called minor):      734\n",
        "True Positives  (correctly called high risk):  3207\n",
        "False Positives (false alarms):                126\n",
        "False Negatives (missed high risk âš ï¸):         249\n",
        "\n",
        "Missed high-risk cases: 249 of 3,456 (7.20%)\n",
        "False alarm rate:        126 of   860 (14.65%)\n",
        "```\n",
        "\n",
        "**Real-Time Inference â€” Confirmed Working:**\n",
        "```\n",
        "Narrative: \"a worker fell from scaffolding and sustained multiple\n",
        "            fractures to the skull...transported to hospital\"\n",
        "â†’ High Risk (88.72%) âœ…\n",
        "\n",
        "Narrative: \"an employee s right middle fingertip was amputated\n",
        "            while pushing meat into an auger\"\n",
        "â†’ Minor (90.19%) âœ…  (outpatient amputation â€” correct OSHA label)\n",
        "\n",
        "Narrative: \"an employee was operating a forklift when it tipped\n",
        "            over...pinned underneath...hospitalized\"\n",
        "â†’ High Risk (89.37%) âœ…\n",
        "\n",
        "Narrative: \"an employee s left index finger was amputated...\n",
        "            treated and released from the emergency room\"\n",
        "â†’ Minor (77.55%) âœ…  (treated and released = Minor in OSHA labeling)\n",
        "```\n",
        "\n",
        "**Key Finding â€” Ground Truth Label Analysis:**\n",
        "During error analysis, we discovered that BERT learned the dataset correctly â€” but the label itself measures **hospital admission status**, not injury severity:\n",
        "\n",
        "```\n",
        "Amputation treated at outpatient facility  â†’  Hospitalized=0  â†’  Minor\n",
        "Worker hospitalized for observation        â†’  Hospitalized=1  â†’  High Risk\n",
        "\n",
        "Evidence from error analysis:\n",
        "The 10 \"most clearly Minor\" cases (lowest HR probability) all\n",
        "described amputations â€” correctly labeled Minor because the worker\n",
        "was treated and released without hospital admission.\n",
        "\n",
        "False positives included:\n",
        "\"worker was hospitalized and his left foot...\" â†’ labeled Minor\n",
        "\"resulting in an eye loss\"                    â†’ labeled Minor\n",
        "Both were likely administrative data entry errors in OSHA records.\n",
        "```\n",
        "\n",
        "BERT correctly learned this administrative distinction. Our initial real-time inference tests failed because we used casual English test sentences (*\"small scrape on his knee\"*) that bear no resemblance to formal OSHA narrative language. Once tested with real OSHA-style narratives, the model performed correctly.\n",
        "\n",
        "**Error Analysis â€” Where BERT Struggles:**\n",
        "```\n",
        "False Negatives (missed High Risk â€” 249 cases):\n",
        "â†’ Out-of-distribution incidents: animal attacks, unusual\n",
        "  machinery, night-shift repairs in rare industrial settings\n",
        "â†’ BERT pattern-matches to common incident types and\n",
        "  misclassifies rare events it hasn't seen enough of\n",
        "\n",
        "False Positives (unnecessary alarms â€” 126 cases):\n",
        "â†’ Incidents describing severe-sounding events that were\n",
        "  administratively classified as outpatient\n",
        "â†’ Some appear to be genuine OSHA data labeling errors\n",
        "  (eye loss labeled Minor, hospitalization mentioned\n",
        "  in a Minor-labeled narrative)\n",
        "\n",
        "High confidence errors: 310 cases (>90% confidence wrong)\n",
        "â†’ Model is certain but incorrect on ambiguous narratives\n",
        "â†’ Reflects inherent noise in the Hospitalized label\n",
        "```\n",
        "\n",
        "**Model Saved:**\n",
        "```\n",
        "Location: /content/drive/MyDrive/OSHA_Project/BERT_OSHA_V2/\n",
        "Files:\n",
        "  config.json             model architecture + label mapping\n",
        "  model.safetensors       trained weights (417.7 MB)\n",
        "  tokenizer.json          vocabulary (30,522 tokens)\n",
        "  tokenizer_config.json   tokenization settings\n",
        "\n",
        "Label mapping (consistent throughout):\n",
        "  0 = Minor     (Hospitalized = 0)\n",
        "  1 = High Risk (Hospitalized >= 1)\n",
        "```\n",
        "\n",
        "**Conclusion:**\n",
        "BERT achieved 91% accuracy and 93% recall on hospitalization prediction across 4,316 held-out validation samples. Error analysis revealed that the model learned the dataset's ground truth correctly â€” including the counterintuitive finding that amputation cases are labeled Minor when treated outpatient. This highlights a fundamental data quality consideration: the OSHA Hospitalized field is an administrative outcome measure, not a clinical severity measure. For production deployment, a composite severity label combining Hospitalized, Amputation, days away from work, and treatment type would produce a more meaningful and clinically accurate target variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "Jv5jj7qG-v-g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV5cl3RI7V1c"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 1: SETUP & DATA LOADING\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/OSHA_Project/\"\n",
        "\n",
        "# Load frozen matrices\n",
        "X_text    = pd.read_pickle(path + \"X_text.pkl\")\n",
        "X_tabular = pd.read_pickle(path + \"X_tabular.pkl\")\n",
        "\n",
        "# ============================================================\n",
        "# Define Target Y\n",
        "# Hospitalized >= 1 â†’ High Risk (1)\n",
        "# Hospitalized  = 0 â†’ Minor     (0)\n",
        "# This is our ground truth â€” consistent with all other notebooks\n",
        "# ============================================================\n",
        "Y_risk = (X_tabular['Hospitalized'].fillna(0) >= 1).astype(int)\n",
        "\n",
        "# Free memory â€” X_tabular no longer needed\n",
        "del X_tabular\n",
        "gc.collect()\n",
        "\n",
        "# Build NLP dataframe â€” remove rows with no narrative\n",
        "df_nlp = pd.DataFrame({\n",
        "    'Narrative':  X_text,\n",
        "    'Risk_Label': Y_risk\n",
        "})\n",
        "df_nlp = df_nlp[\n",
        "    df_nlp['Narrative'] != \"No Narrative Provided\"\n",
        "].reset_index(drop=True)\n",
        "\n",
        "print(\"âœ… Data Loaded Successfully\")\n",
        "print(f\"   NLP Matrix Shape: {df_nlp.shape}\")\n",
        "print(f\"\\n   Class Distribution:\")\n",
        "print(f\"   High Risk (1): {(df_nlp['Risk_Label']==1).sum():,} \"\n",
        "      f\"({(df_nlp['Risk_Label']==1).mean():.2%})\")\n",
        "print(f\"   Minor     (0): {(df_nlp['Risk_Label']==0).sum():,} \"\n",
        "      f\"({(df_nlp['Risk_Label']==0).mean():.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 2: TOKENIZATION\n",
        "#\n",
        "# WHY BERT needs tokenization:\n",
        "# BERT doesn't read words â€” it reads token IDs.\n",
        "# \"fracture\" â†’ [19173]\n",
        "# \"conveyor\"  â†’ [24040]\n",
        "#\n",
        "# Every sentence gets:\n",
        "# 1. Converted to token IDs (input_ids)\n",
        "# 2. An attention mask â€” 1 = real token, 0 = padding\n",
        "#    This tells BERT \"pay attention here, ignore padding\"\n",
        "#\n",
        "# MAX_LEN = 128:\n",
        "# OSHA narratives are short. 128 tokens captures ~95% fully.\n",
        "# Longer = more GPU memory, slower training, minimal gain.\n",
        "# ============================================================\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "print(\"Loading BERT tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "print(\"Tokenizing all narratives...\")\n",
        "tokens = tokenizer(\n",
        "    df_nlp['Narrative'].tolist(),\n",
        "    max_length=MAX_LEN,\n",
        "    padding='max_length',   # pad short sentences to exactly 128\n",
        "    truncation=True,        # cut sentences longer than 128\n",
        "    return_tensors='pt'     # return PyTorch tensors\n",
        ")\n",
        "\n",
        "X_input_ids      = tokens['input_ids']\n",
        "X_attention_mask = tokens['attention_mask']\n",
        "Y_labels         = torch.tensor(df_nlp['Risk_Label'].values)\n",
        "\n",
        "print(f\"\\nâœ… Tokenization Complete\")\n",
        "print(f\"   Input IDs shape:      {X_input_ids.shape}\")\n",
        "print(f\"   Attention mask shape: {X_attention_mask.shape}\")\n",
        "print(f\"   Labels shape:         {Y_labels.shape}\")\n",
        "print(f\"   Memory used:          ~{X_input_ids.element_size() * X_input_ids.nelement() / 1e6:.0f} MB\")"
      ],
      "metadata": {
        "id": "gsg1MRyJ8ZHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 3: TRAIN/TEST SPLIT + DATALOADERS\n",
        "#\n",
        "# WHY stratify?\n",
        "# Without it, the 80/20 split might accidentally put\n",
        "# more Minor cases in train and more High Risk in test\n",
        "# or vice versa. Stratify guarantees exact class ratio\n",
        "# is preserved in both sets.\n",
        "#\n",
        "# WHY DataLoaders?\n",
        "# GPU processes data in batches. DataLoader handles:\n",
        "# - Batching (groups of 16 samples)\n",
        "# - Shuffling (RandomSampler for train)\n",
        "# - Sequential order (SequentialSampler for validation)\n",
        "# ============================================================\n",
        "from torch.utils.data import (TensorDataset, DataLoader,\n",
        "                               RandomSampler, SequentialSampler)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Split â€” same random_state=42 for reproducibility\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
        "    X_input_ids, Y_labels,\n",
        "    test_size=0.2, random_state=42, stratify=Y_labels\n",
        ")\n",
        "train_masks, val_masks, _, _ = train_test_split(\n",
        "    X_attention_mask, Y_labels,\n",
        "    test_size=0.2, random_state=42, stratify=Y_labels\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# Class weights â€” tell loss function to penalize\n",
        "# minority class (Minor) mistakes more heavily\n",
        "# Formula: W_i = N_total / (n_classes Ã— N_i)\n",
        "# ============================================================\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(Y_labels.numpy()),\n",
        "    y=train_labels.numpy()\n",
        ")\n",
        "weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "print(\"âœ… Split Complete\")\n",
        "print(f\"   Train size: {len(train_labels):,}  \"\n",
        "      f\"({(train_labels==0).sum():,} minor, {(train_labels==1).sum():,} high risk)\")\n",
        "print(f\"   Val size:   {len(val_labels):,}  \"\n",
        "      f\"({(val_labels==0).sum():,} minor, {(val_labels==1).sum():,} high risk)\")\n",
        "print(f\"\\n   Class weights: Minor={weights_tensor[0]:.4f}, \"\n",
        "      f\"High Risk={weights_tensor[1]:.4f}\")\n",
        "\n",
        "# Build DataLoaders\n",
        "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "val_dataset   = TensorDataset(val_inputs,   val_masks,   val_labels)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler=RandomSampler(train_dataset),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    sampler=SequentialSampler(val_dataset),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f\"\\n   Training batches:   {len(train_dataloader)}\")\n",
        "print(f\"   Validation batches: {len(val_dataloader)}\")"
      ],
      "metadata": {
        "id": "gj202fi38ZJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 4: MODEL INITIALIZATION\n",
        "#\n",
        "# WHY BertForSequenceClassification?\n",
        "# It's BERT with a classification head on top.\n",
        "# Architecture:\n",
        "#   Input tokens\n",
        "#       â†“\n",
        "#   12 Transformer layers (attention + feedforward)\n",
        "#       â†“\n",
        "#   [CLS] token representation (sentence summary)\n",
        "#       â†“\n",
        "#   Dropout (prevents overfitting)\n",
        "#       â†“\n",
        "#   Linear layer (768 â†’ 2)\n",
        "#       â†“\n",
        "#   Logits [Minor_score, HighRisk_score]\n",
        "#\n",
        "# WHY AdamW optimizer?\n",
        "# Adam with Weight Decay. Standard for BERT fine-tuning.\n",
        "# lr=2e-5 is the recommended learning rate for BERT fine-tuning\n",
        "# â€” large enough to learn, small enough not to destroy\n",
        "# pre-trained weights.\n",
        "#\n",
        "# WHY linear scheduler with warmup?\n",
        "# Learning rate starts at 0, ramps up for warmup_steps,\n",
        "# then linearly decays to 0. Prevents large updates early\n",
        "# in training that could corrupt pre-trained knowledge.\n",
        "# ============================================================\n",
        "from transformers import (BertForSequenceClassification,\n",
        "                          get_linear_schedule_with_warmup)\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "\n",
        "# GPU check\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Hardware: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# Load pre-trained BERT with classification head\n",
        "# CONSISTENT label mapping throughout entire notebook:\n",
        "# 0 = Minor, 1 = High Risk\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=2,\n",
        "    id2label={0: \"Minor\", 1: \"High Risk\"},\n",
        "    label2id={\"Minor\": 0, \"High Risk\": 1},\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,    # recommended for BERT fine-tuning\n",
        "    eps=1e-8    # numerical stability\n",
        ")\n",
        "\n",
        "# Training schedule\n",
        "EPOCHS      = 5\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "warmup_steps = total_steps // 10  # 10% warmup\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# Weighted loss function\n",
        "# Cross Entropy because we have 2 classes (not MSE)\n",
        "# Weighted because Minor class is heavily underrepresented\n",
        "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor.to(device))\n",
        "\n",
        "print(f\"\\nâœ… Model Initialized\")\n",
        "print(f\"   Parameters:      {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"   Trainable:       {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "print(f\"   Epochs:          {EPOCHS}\")\n",
        "print(f\"   Total steps:     {total_steps:,}\")\n",
        "print(f\"   Warmup steps:    {warmup_steps:,}\")\n",
        "print(f\"   Label mapping:   0=Minor, 1=High Risk (consistent)\")"
      ],
      "metadata": {
        "id": "FRo1lHuL8ZL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 5: TRAINING LOOP\n",
        "#\n",
        "# Each epoch:\n",
        "# 1. Forward pass  â†’ model makes predictions (logits)\n",
        "# 2. Loss          â†’ how wrong was it? (Cross Entropy)\n",
        "# 3. Backward pass â†’ calculate gradients (which direction to adjust)\n",
        "# 4. Clip gradients â†’ prevent exploding gradients (cap at 1.0)\n",
        "# 5. Optimizer step â†’ update weights in the right direction\n",
        "# 6. Scheduler step â†’ adjust learning rate\n",
        "#\n",
        "# model.train() vs model.eval():\n",
        "# train() â†’ enables dropout (adds noise, prevents overfitting)\n",
        "# eval()  â†’ disables dropout (deterministic predictions)\n",
        "# ============================================================\n",
        "import time\n",
        "\n",
        "print(\"=\" * 55)\n",
        "print(\"BERT FINE-TUNING â€” 5 Epochs on OSHA Narratives\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "training_history = []\n",
        "\n",
        "for epoch_i in range(EPOCHS):\n",
        "    print(f\"\\n{'='*55}\")\n",
        "    print(f\"Epoch {epoch_i + 1} / {EPOCHS}\")\n",
        "    print(f\"{'='*55}\")\n",
        "\n",
        "    # â”€â”€ TRAINING PHASE â”€â”€\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids  = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels     = batch[2].to(device)\n",
        "\n",
        "        # Clear gradients from previous step\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass â†’ get raw scores (logits)\n",
        "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
        "        logits  = outputs.logits\n",
        "\n",
        "        # Calculate weighted cross entropy loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Backward pass â†’ compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients â†’ prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update weights and learning rate\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Progress report every 200 batches\n",
        "        if step % 200 == 0 and step != 0:\n",
        "            elapsed = time.time() - t0\n",
        "            print(f\"  Batch {step:>4} / {len(train_dataloader)}  \"\n",
        "                  f\"Loss: {loss.item():.4f}  \"\n",
        "                  f\"Elapsed: {elapsed:.0f}s\")\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # â”€â”€ VALIDATION PHASE â”€â”€\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    val_preds, val_true = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
        "\n",
        "        logits    = outputs.logits\n",
        "        val_loss  = loss_fn(logits, b_labels)\n",
        "        total_val_loss += val_loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        val_preds.extend(preds)\n",
        "        val_true.extend(b_labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    val_accuracy = np.mean(np.array(val_preds) == np.array(val_true))\n",
        "\n",
        "    training_history.append({\n",
        "        'epoch':      epoch_i + 1,\n",
        "        'train_loss': avg_train_loss,\n",
        "        'val_loss':   avg_val_loss,\n",
        "        'val_acc':    val_accuracy\n",
        "    })\n",
        "\n",
        "    print(f\"\\n  Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Val Loss:   {avg_val_loss:.4f}\")\n",
        "    print(f\"  Val Acc:    {val_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*55}\")\n",
        "print(\"âœ… Training Complete!\")\n",
        "print(f\"{'='*55}\")\n",
        "\n",
        "# Plot training curves\n",
        "history_df = pd.DataFrame(training_history)\n",
        "fig, axes  = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axes[0].plot(history_df['epoch'], history_df['train_loss'],\n",
        "             'b-o', label='Train Loss')\n",
        "axes[0].plot(history_df['epoch'], history_df['val_loss'],\n",
        "             'r-o', label='Val Loss')\n",
        "axes[0].set_title('Loss per Epoch')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].plot(history_df['epoch'], history_df['val_acc'],\n",
        "             'g-o', label='Val Accuracy')\n",
        "axes[1].set_title('Validation Accuracy per Epoch')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('BERT Training History â€” 5 Epochs', fontsize=13)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pcckcn-x8ZPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 6: FULL EVALUATION\n",
        "# ============================================================\n",
        "print(\"Running full evaluation on validation set...\\n\")\n",
        "\n",
        "model.eval()\n",
        "all_preds, all_true, all_probs = [], [], []\n",
        "\n",
        "for batch in val_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
        "\n",
        "    logits      = outputs.logits.detach().cpu()\n",
        "    probs       = torch.nn.functional.softmax(logits, dim=-1).numpy()\n",
        "    preds       = np.argmax(probs, axis=1)\n",
        "    label_ids   = b_labels.cpu().numpy()\n",
        "\n",
        "    all_preds.extend(preds)\n",
        "    all_true.extend(label_ids)\n",
        "    all_probs.extend(probs)\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_true  = np.array(all_true)\n",
        "all_probs = np.array(all_probs)\n",
        "\n",
        "# Classification Report\n",
        "print(\"=\" * 55)\n",
        "print(\"BERT Classification Report\")\n",
        "print(\"=\" * 55)\n",
        "print(classification_report(\n",
        "    all_true, all_preds,\n",
        "    target_names=['Minor (0)', 'High Risk (1)']\n",
        "))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(all_true, all_preds)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm,\n",
        "    display_labels=['Minor (0)', 'High Risk (1)']\n",
        ").plot(ax=ax, colorbar=False, cmap='Blues')\n",
        "ax.set_title(\"BERT â€” Confusion Matrix (Validation Set)\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"True Negatives  (correctly called minor):        {tn}\")\n",
        "print(f\"True Positives  (correctly called high risk):    {tp}\")\n",
        "print(f\"False Positives (false alarms):                  {fp}\")\n",
        "print(f\"False Negatives (missed high risk âš ï¸):           {fn}\")\n",
        "print(f\"\\nMissed high-risk: {fn} of {fn+tp} ({fn/(fn+tp):.2%})\")\n",
        "print(f\"False alarms:     {fp} of {fp+tn} ({fp/(fp+tn):.2%})\")"
      ],
      "metadata": {
        "id": "lq8q8KBf8ZQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 7: REAL-TIME INFERENCE\n",
        "#\n",
        "# KEY LESSON FROM PREVIOUS NOTEBOOK:\n",
        "# The predict function must use padding='max_length'\n",
        "# AND pass attention_mask explicitly.\n",
        "# This matches training tokenization exactly and\n",
        "# prevents the model from collapsing to one class.\n",
        "# ============================================================\n",
        "\n",
        "def predict_incident(text):\n",
        "    \"\"\"\n",
        "    Predict risk level from raw incident narrative text.\n",
        "\n",
        "    Args:\n",
        "        text: incident description string\n",
        "\n",
        "    Returns:\n",
        "        label:      'Minor' or 'High Risk'\n",
        "        confidence: percentage 0-100\n",
        "\n",
        "    Notes:\n",
        "        - Uses padding='max_length' to match training tokenization\n",
        "        - Uses model.config.id2label â€” never hardcoded mapping\n",
        "        - Consistent: 0=Minor, 1=High Risk\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        padding='max_length',    # must match training\n",
        "        max_length=MAX_LEN,      # must match training (128)\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask']\n",
        "        )\n",
        "\n",
        "    probs      = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    pred_idx   = torch.argmax(probs, dim=1).item()\n",
        "    confidence = probs[0][pred_idx].item() * 100\n",
        "\n",
        "    # Always use model's own config â€” never hardcode\n",
        "    label = model.config.id2label[pred_idx]\n",
        "\n",
        "    return label, confidence\n",
        "\n",
        "# ============================================================\n",
        "# Test suite â€” covers all severity levels\n",
        "# ============================================================\n",
        "\n",
        "test_cases = [\n",
        "    # High Risk â€” hospitalized\n",
        "    (\"a worker fell from scaffolding and sustained multiple fractures \"\n",
        "     \"to the skull and was transported to the hospital for emergency surgery.\",\n",
        "     \"High Risk\"),\n",
        "\n",
        "    # Minor â€” amputation but outpatient\n",
        "    (\"an employee s right middle fingertip was amputated while \"\n",
        "     \"pushing meat into an auger.\",\n",
        "     \"Minor\"),\n",
        "\n",
        "    # High Risk â€” explicitly hospitalized\n",
        "    (\"an employee was operating a forklift when it tipped over. \"\n",
        "     \"the employee was pinned underneath and hospitalized for \"\n",
        "     \"injuries to the chest and ribs.\",\n",
        "     \"High Risk\"),\n",
        "\n",
        "    # Minor â€” treated and released\n",
        "    (\"an employee s left index finger was amputated at the first \"\n",
        "     \"digit while operating a punch press. the employee was treated \"\n",
        "     \"and released from the emergency room.\",\n",
        "     \"Minor\"),\n",
        "\n",
        "    # High Risk â€” chemical exposure + hospitalized\n",
        "    (\"a worker was exposed to sulfuric acid fumes and suffered \"\n",
        "     \"severe chemical burns. the worker was hospitalized for treatment.\",\n",
        "     \"High Risk\"),\n",
        "\n",
        "    # Minor â€” first aid only\n",
        "    (\"an employee caught his fingertip in a conveyor belt. \"\n",
        "     \"first aid was administered on site. no further treatment needed.\",\n",
        "     \"Minor\"),\n",
        "\n",
        "    # Ambiguous\n",
        "    (\"an employee was operating a punch press when his finger \"\n",
        "     \"was caught. the extent of the injury was not immediately clear.\",\n",
        "     \"Ambiguous\"),\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "print(\"=\" * 65)\n",
        "print(\"BERT Real-Time Incident Risk Classifier\")\n",
        "print(\"Label mapping: 0=Minor, 1=High Risk (consistent)\")\n",
        "print(\"=\" * 65)\n",
        "\n",
        "correct = 0\n",
        "total_known = 0\n",
        "\n",
        "for i, (text, expected) in enumerate(test_cases, 1):\n",
        "    label, conf = predict_incident(text)\n",
        "    icon   = \"ðŸ”´\" if label == \"High Risk\" else \"ðŸŸ¢\"\n",
        "\n",
        "    if expected != \"Ambiguous\":\n",
        "        is_correct = (label == expected)\n",
        "        status     = \"âœ…\" if is_correct else \"âŒ\"\n",
        "        correct   += int(is_correct)\n",
        "        total_known += 1\n",
        "    else:\n",
        "        status = \"ðŸ¤”\"\n",
        "\n",
        "    print(f\"\\nTest {i}: {icon} {label} ({conf:.2f}%) {status}\")\n",
        "    print(f\"  Expected:  {expected}\")\n",
        "    print(f\"  Narrative: {text[:80]}...\")\n",
        "\n",
        "print(f\"\\n{'='*65}\")\n",
        "print(f\"Test accuracy: {correct}/{total_known} = {correct/total_known:.0%}\")"
      ],
      "metadata": {
        "id": "g2jU_UoU8ZS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 8: SHAP â€” Word-Level Explanations\n",
        "#\n",
        "# WHY SHAP?\n",
        "# The model gives a prediction. SHAP explains WHY.\n",
        "# It assigns each word a score:\n",
        "#   Positive score â†’ pushed toward High Risk\n",
        "#   Negative score â†’ pushed toward Minor\n",
        "#\n",
        "# FIX from previous notebook:\n",
        "# Original SHAP function was missing attention_mask.\n",
        "# BERT needs both input_ids AND attention_mask.\n",
        "# Without attention_mask, BERT treats padding tokens as\n",
        "# real words â€” completely distorting the explanation.\n",
        "# ============================================================\n",
        "!pip install shap -q\n",
        "import shap\n",
        "\n",
        "def predict_proba_for_shap(texts):\n",
        "    \"\"\"\n",
        "    SHAP-compatible wrapper.\n",
        "    Correctly passes attention_mask to BERT.\n",
        "    Returns probability array shape (n_samples, 2).\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        list(texts),\n",
        "        padding='max_length',\n",
        "        max_length=MAX_LEN,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask']  # â† critical fix\n",
        "        )\n",
        "\n",
        "    probs = torch.nn.functional.softmax(\n",
        "        outputs.logits, dim=-1\n",
        "    ).cpu().numpy()\n",
        "\n",
        "    return probs\n",
        "\n",
        "# Initialize explainer\n",
        "print(\"Initializing SHAP explainer...\")\n",
        "explainer = shap.Explainer(predict_proba_for_shap, tokenizer)\n",
        "\n",
        "# Explain two contrasting predictions\n",
        "shap_texts = [\n",
        "    \"Worker's hand got stuck in a conveyor belt leading to severe fracture.\",\n",
        "    \"An employee slipped on water in the breakroom and got a small scrape.\"\n",
        "]\n",
        "\n",
        "print(\"Computing SHAP values...\\n\")\n",
        "shap_values = explainer(shap_texts)\n",
        "\n",
        "print(\"=\" * 55)\n",
        "print(\"HIGH RISK â€” Words driving this prediction (red = High Risk)\")\n",
        "print(\"=\" * 55)\n",
        "shap.plots.text(shap_values[0])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 55)\n",
        "print(\"MINOR â€” Words driving this prediction (blue = Minor)\")\n",
        "print(\"=\" * 55)\n",
        "shap.plots.text(shap_values[1])"
      ],
      "metadata": {
        "id": "VmJSZ_FT8ZVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 9: ERROR ANALYSIS\n",
        "# Where does BERT struggle and why?\n",
        "# ============================================================\n",
        "print(\"Analyzing BERT's mistakes...\\n\")\n",
        "\n",
        "val_df = pd.DataFrame({\n",
        "    'Narrative': [\n",
        "        tokenizer.decode(t, skip_special_tokens=True)\n",
        "        for t in val_inputs\n",
        "    ],\n",
        "    'Actual':    all_true,\n",
        "    'Predicted': all_preds,\n",
        "    'Confidence': [max(p) * 100 for p in all_probs]\n",
        "})\n",
        "\n",
        "val_df['Actual_Label']    = val_df['Actual'].map(\n",
        "    {0: 'Minor', 1: 'High Risk'})\n",
        "val_df['Predicted_Label'] = val_df['Predicted'].map(\n",
        "    {0: 'Minor', 1: 'High Risk'})\n",
        "val_df['Correct']         = val_df['Actual'] == val_df['Predicted']\n",
        "\n",
        "errors = val_df[~val_df['Correct']].copy()\n",
        "\n",
        "print(f\"Total errors:    {len(errors):,} of {len(val_df):,} \"\n",
        "      f\"({len(errors)/len(val_df):.2%})\")\n",
        "print(f\"False Positives: {fp} (called High Risk, was Minor)\")\n",
        "print(f\"False Negatives: {fn} (called Minor, was High Risk âš ï¸)\")\n",
        "\n",
        "# High confidence wrong predictions â€” most concerning\n",
        "high_conf_errors = errors[errors['Confidence'] > 90].sort_values(\n",
        "    'Confidence', ascending=False)\n",
        "print(f\"\\nHigh confidence errors (>90%): {len(high_conf_errors)}\")\n",
        "print(\"These are cases where BERT was very wrong very confidently:\\n\")\n",
        "\n",
        "print(\"--- False Negatives: Missed High Risk Cases ---\")\n",
        "fn_cases = errors[\n",
        "    (errors['Actual'] == 1) &\n",
        "    (errors['Predicted'] == 0)\n",
        "].sort_values('Confidence', ascending=False).head(5)\n",
        "\n",
        "for _, row in fn_cases.iterrows():\n",
        "    print(f\"\\n  Narrative:  {row['Narrative'][:100]}...\")\n",
        "    print(f\"  Actual:     {row['Actual_Label']}  \"\n",
        "          f\"â†’  Predicted: {row['Predicted_Label']} \"\n",
        "          f\"({row['Confidence']:.1f}% confident)\")\n",
        "\n",
        "print(\"\\n--- False Positives: Unnecessary Alarms ---\")\n",
        "fp_cases = errors[\n",
        "    (errors['Actual'] == 0) &\n",
        "    (errors['Predicted'] == 1)\n",
        "].sort_values('Confidence', ascending=False).head(5)\n",
        "\n",
        "for _, row in fp_cases.iterrows():\n",
        "    print(f\"\\n  Narrative:  {row['Narrative'][:100]}...\")\n",
        "    print(f\"  Actual:     {row['Actual_Label']}  \"\n",
        "          f\"â†’  Predicted: {row['Predicted_Label']} \"\n",
        "          f\"({row['Confidence']:.1f}% confident)\")"
      ],
      "metadata": {
        "id": "dFVIb0VU8ZX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 10: SAVE MODEL TO DRIVE\n",
        "# ============================================================\n",
        "save_path = path + \"BERT_OSHA_V2\"\n",
        "\n",
        "print(f\"Saving model to: {save_path}\")\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"\\nâœ… Model saved successfully!\")\n",
        "print(f\"   Location: {save_path}\")\n",
        "print(f\"   Files saved:\")\n",
        "print(f\"   - config.json          (model architecture)\")\n",
        "print(f\"   - model.safetensors    (trained weights ~417MB)\")\n",
        "print(f\"   - tokenizer.json       (vocabulary)\")\n",
        "print(f\"   - tokenizer_config.json\")\n",
        "\n",
        "# Final summary\n",
        "print(f\"\\n{'='*55}\")\n",
        "print(\"BERT OSHA V2 â€” Final Summary\")\n",
        "print(f\"{'='*55}\")\n",
        "print(f\"Model:          bert-base-uncased fine-tuned\")\n",
        "print(f\"Task:           Incident narrative risk classification\")\n",
        "print(f\"Training data:  {len(train_labels):,} OSHA narratives\")\n",
        "print(f\"Epochs:         5\")\n",
        "print(f\"Label mapping:  0=Minor, 1=High Risk (consistent)\")\n",
        "print(f\"Validation acc: check classification report above\")\n",
        "print(f\"Saved to:       {save_path}\")"
      ],
      "metadata": {
        "id": "M6WJBlOO8ZaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wrNcK8pd8Zc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNElzURb8ZgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d43Su78bKwLP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}